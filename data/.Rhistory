random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
#calculate words
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
#create wordcloud
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
#create wordcloud
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,words>2
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,min=2,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,min=4,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,min=2,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,min=2,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,min=2,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.2, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.8, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
par(family=("Heiti TC Light"))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
par(family=("Microsolf JengHei"))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
par(family=("Heiti TC Light"))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
install.packages('wordcloud2')
wordcloud2(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE, shape='triangle',size=0.3)
library(wordcloud2)
wordcloud2(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE, shape='triangle',size=0.3)
wordcloud2(freqFrame$Var1,freqFrame$Freq)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud2(freqFrame$Var1,freqFrame$Freq)
wordcloud2(freqFrame)
wordcloud2(freqFrame, minSize=10)
wordcloud2(freqFrame, minSize=10, fontFamily='Microsolf Jenghei')
wordcloud2(freqFrame, minSize=10, color='randon_dark')
wordcloud2(freqFrame, minSize=10, color='randon-dark')
wordcloud2(freqFrame, minSize=10, color='randon-dark')
wordcloud2(freqFrame, minSize=10)
wordcloud2(freqFrame, minSize=20, gridSize=20)
wordcloud2(freqFrame, minSize=10, gridSize=20)
wordcloud2(freqFrame, minSize=10, gridSize=5)
wordcloud2(shape='circle', freqFrame, minSize=10, gridSize=5)
wordcloud2(shape='circle', freqFrame, minSize=10, gridSize=10)
wordcloud2(fontFamily = "微软雅黑", shape='circle', freqFrame, minSize=10, gridSize=5)
wordcloud2(fontFamily = "微軟雅黑", shape='circle', freqFrame, minSize=10, gridSize=5)
wordcloud2(shape='star', freqFrame, minSize=10, gridSize=5)
wordcloud2(freqFrame, minSize=10, gridSize=5)
#create wordcloud
wordcloud2(freqFrame, minSize=10, gridSize=5)
View(freqFrame)
class(freqFrame)
new_freqFrame = subset(freqFrame, len(Var1)>=2)
new_freqFrame = subset(freqFrame, length(Var1)>=2)
wordcloud2(new_freqFrame, minSize=10, gridSize=5)
View(new_freqFrame)
View(new_freqFrame)
length('日本')
length('你')
c = ("日本", "你")
c = c("日本", "你")
lenght(c)
length(c)
#plotting
filter(gender_map, Series.Name == 'Population, female (% of total)')%>%
select('2010')%>%
ggplot() +
geom_sf(aes(fill=`2010`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
gender_map%>%
filter(Series.Name == 'Population, female (% of total)')
setwd("D:/2018.07 R_DataAnalysis/2018SUMMER_R/data")
#import data
library(sf)
library(ggplot2)
worldmap <- st_read("TM_WORLD_BORDERS-0.3.shp",stringsAsFactors=FALSE,quiet=TRUE)
names(worldmap)[3] <- paste('Country.Code')
worldmap <- st_transform(worldmap, "+init=esri:54030")
raw_gender <- read.csv('Gender_wewant.csv')
gender_map <- merge(worldmap, raw_gender, by="Country.Code")
library(stringr)
for (i in 15:ncol(gender_map)-1){
names(gender_map)[i] <- str_sub(names(gender_map)[i],-5,-2)
if((i >= 17) == (i < 41)){
gender_map[i+1] <- (gender_map[[i+1]] + gender_map[[i]] + gender_map[[i-1]] + gender_map[[i-2]]) /2
}
}
ath <- read.csv("athlete_wewant.csv")
ath['num']=1
ath1<-ath%>%filter(Year>=1990)%>%group_by(NOC,Year,Sex)%>%summarize(Medal_sum=sum(Medal_score),people=sum(num))
ath1A<-ath%>%filter(Year>=1990)%>%group_by(NOC,Year)%>%summarize(join_people=sum(num))
ath1B<-unite(ath1A,NOC,NOC,Year,sep='_')
ath2A<-ath1%>%filter(Sex=="F")
ath2B<-unite(ath2A,NOC,NOC,Year,sep='_')
ath2C<-data.frame(ath2B[,1],ath2B[,3])
ath3<-merge(ath2C,ath1B,by="NOC")
ath3["Fscore"]=ath3[,2]/ath3[,3]
gender_map%>%
filter(Series.Name == 'Population, female (% of total)')%>%
select('2010')%>%
ggplot() +
geom_sf(aes(fill=`2010`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
setwd("D:/2018.07 R_DataAnalysis/2018SUMMER_R/data")
#import data
library(sf)
library(ggplot2)
worldmap <- st_read("TM_WORLD_BORDERS-0.3.shp",stringsAsFactors=FALSE,quiet=TRUE)
names(worldmap)[3] <- paste('Country.Code')
worldmap <- st_transform(worldmap, "+init=esri:54030")
raw_gender <- read.csv('Gender_wewant.csv')
gender_map <- merge(worldmap, raw_gender, by="Country.Code")
library(stringr)
for (i in 15:ncol(gender_map)-1){
names(gender_map)[i] <- str_sub(names(gender_map)[i],-5,-2)
if(i < 41){
gender_map[i+1] <- (gender_map[[i+1]] + gender_map[[i]]) /2
}
}
gender_map%>%
filter(Series.Name == 'Population, female (% of total)')%>%
select('2010')%>%
ggplot() +
geom_sf(aes(fill=`2010`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
gender_map%>%
filter(Country.code == 'RUS')
str(gender_map$Series.Name)
as.matric(gender_map)%>%
filter(Country.code == 'RUS')
as.matrix(gender_map)%>%
filter(Country.code == 'RUS')
filter(gender_map, Country.code == 'RUS')
setwd("D:/2018.07 R_DataAnalysis/2018SUMMER_R/data")
#import data
library(sf)
library(ggplot2)
worldmap <- st_read("TM_WORLD_BORDERS-0.3.shp",stringsAsFactors=FALSE,quiet=TRUE)
names(worldmap)[3] <- paste('Country.Code')
worldmap <- st_transform(worldmap, "+init=esri:54030")
raw_gender <- read.csv('Gender_wewant.csv')
gender_map <- merge(worldmap, raw_gender, by="Country.Code")
library(stringr)
for (i in 15:ncol(gender_map)-1){
names(gender_map)[i] <- str_sub(names(gender_map)[i],-5,-2)
if(i < 41){
gender_map[i+1] <- (gender_map[[i+1]] + gender_map[[i]]) /2
}
}
#plotting
gender_map%>%
filter(Series.Name == 'Employers, female (% of female employment) (modeled ILO estimate)')%>%
select('2010')%>%
ggplot() +
geom_sf(aes(fill=`2010`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
setwd("D:/2018.07 R_DataAnalysis/2018SUMMER_R/data")
#import data
library(sf)
library(ggplot2)
worldmap <- st_read("TM_WORLD_BORDERS-0.3.shp",stringsAsFactors=FALSE,quiet=TRUE)
names(worldmap)[3] <- paste('Country.Code')
worldmap <- st_transform(worldmap, "+init=esri:54030")
raw_gender <- read.csv('Gender_wewant.csv')
gender_map <- merge(worldmap, raw_gender, by="Country.Code")
library(stringr)
for (i in 15:ncol(gender_map)-1){
names(gender_map)[i] <- str_sub(names(gender_map)[i],-5,-2)
if(i < 41){
gender_map[i+1] <- (gender_map[[i+1]] + gender_map[[i]]) /2
}
}
#plotting
gender_map%>%
filter(Series.Name == 'Employers, female (% of female employment) (modeled ILO estimate)')%>%
select('2016')%>%
ggplot() +
geom_sf(aes(fill=`2010`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
gender_map%>%
filter(, Country.code == 'RUS')
gender_map%>%
filter(Country.code == 'RUS')
gender_map%>%
filter(gender_map$Country.code == 'RUS')
setwd("D:/2018.07 R_DataAnalysis/2018SUMMER_R/data")
#import data
library(sf)
library(ggplot2)
worldmap <- st_read("TM_WORLD_BORDERS-0.3.shp",stringsAsFactors=FALSE,quiet=TRUE)
names(worldmap)[3] <- paste('Country.Code')
worldmap <- st_transform(worldmap, "+init=esri:54030")
raw_gender <- read.csv('Gender_wewant.csv')
gender_map <- merge(worldmap, raw_gender, by="Country.Code")
gender_map%>%
filter(Country.code == 'RUS')
gender_map%>%
dplyr::filter(Country.code == 'RUS')
dplyr::filter(gender_map, Country.code == 'RUS')
filter(gender_map, Country.code == 'RUS')
filter(gender_map, Country.code == 'RUS')
library(dplyr)
gender_map%>%
filter(Country.code == 'RUS')
setwd("D:/2018.07 R_DataAnalysis/2018SUMMER_R/data")
#import data
library(sf)
library(ggplot2)
worldmap <- st_read("TM_WORLD_BORDERS-0.3.shp",stringsAsFactors=FALSE,quiet=TRUE)
names(worldmap)[3] <- paste('Country.Code')
worldmap <- st_transform(worldmap, "+init=esri:54030")
raw_gender <- read.csv('Gender_wewant.csv')
gender_map <- merge(worldmap, raw_gender, by="Country.Code")
library(stringr)
for (i in 15:ncol(gender_map)-1){
names(gender_map)[i] <- str_sub(names(gender_map)[i],-5,-2)
if(i < 41){
gender_map[i+1] <- (gender_map[[i+1]] + gender_map[[i]]) /2
}
gender_map[gender_map$Series.Name == 'Employers, female (% of female employment) (modeled ILO estimate)']
]
gender_map[gender_map$Series.Name == 'Employers, female (% of female employment) (modeled ILO estimate)']
gender_map$Series.Name
filter(gender_map, Country.Code == 'RUS')
setwd("D:/2018.07 R_DataAnalysis/2018SUMMER_R/data")
#import data
library(sf)
library(ggplot2)
worldmap <- st_read("TM_WORLD_BORDERS-0.3.shp",stringsAsFactors=FALSE,quiet=TRUE)
names(worldmap)[3] <- paste('Country.Code')
worldmap <- st_transform(worldmap, "+init=esri:54030")
raw_gender <- read.csv('Gender_wewant.csv')
gender_map <- merge(worldmap, raw_gender, by="Country.Code")
library(stringr)
for (i in 15:ncol(gender_map)-1){
names(gender_map)[i] <- str_sub(names(gender_map)[i],-5,-2)
if(i < 41){
gender_map[i+1] <- (gender_map[[i+1]] + gender_map[[i]]) /2
}
}
filter(gender_map, Country.Code == 'RUS')
gender_map%>%
filter(Country.code == 'RUS')
gender_map%>%
filter('Country.code' == 'RUS')
gender_map%>%
filter('Series.Name' == 'Population, female (% of total)')%>%
select('2010')%>%
ggplot() +
geom_sf(aes(fill=`2010`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
gender_map%>%
filter('Series.Name' == 'Population, female (% of total)')%>%
select('2010')%>%
ggplot() +
geom_sf(aes(fill='2010'))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
gender_map%>%
filter('Series.Name' == 'Population, female (% of total)')%>%
select('2010')%>%
ggplot() +
geom_sf(aes(fill=`2014`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
gender_map%>%
filter('Series.Name' == 'Population, female (% of total)')%>%
select('2010')%>%
ggplot() +
geom_sf(aes(fill=`'2014'`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
gender_map%>%
filter('Series.Name' == 'Population, female (% of total)')%>%
select('2014')%>%
ggplot() +
geom_sf(aes(fill=2014))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
#plotting
gender_map%>%
filter('Series.Name' == 'Population, female (% of total)')%>%
select('2014')%>%
ggplot() +
geom_sf(aes(fill='2014'))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
#plotting
gender_map%>%
filter('Series.Name' == 'Population, female (% of total)')%>%
select('2014')%>%
ggplot() +
geom_sf(aes(fill=`2014`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
gender_map%>%
filter('Series.Name' == 'Population, female (% of total)')%>%
select('2014')
gender_map%>%
filter(Series.Name == 'Population, female (% of total)')%>%
select('2014')%>%
ggplot() +
geom_sf(aes(fill=`2014`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
ath<- read.csv("athlete_wewant.csv")
ath['num']=1
ath1<-ath%>%filter(Year>=1990)%>%group_by(NOC,Year,Sex)%>%summarize(Medal_sum=sum(Medal_score),people=sum(num))
ath1A<-ath%>%filter(Year>=1990)%>%group_by(NOC,Year)%>%summarize(join_people=sum(num))
ath1B<-unite(ath1A,NOC,NOC,Year,sep='_')
ath2A<-ath1%>%filter(Sex=="F")
ath2B<-unite(ath2A,NOC,NOC,Year,sep='_')
ath2C<-data.frame(ath2B[,1],ath2B[,3])
ath3<-merge(ath2C,ath1B,by="NOC")
ath3["Fscore"]=ath3[,2]/ath3[,3]
library(tidyr)
ath<- read.csv("athlete_wewant.csv")
ath['num']=1
ath1<-ath%>%filter(Year>=1990)%>%group_by(NOC,Year,Sex)%>%summarize(Medal_sum=sum(Medal_score),people=sum(num))
ath1A<-ath%>%filter(Year>=1990)%>%group_by(NOC,Year)%>%summarize(join_people=sum(num))
ath1B<-unite(ath1A,NOC,NOC,Year,sep='_')
ath2A<-ath1%>%filter(Sex=="F")
ath2B<-unite(ath2A,NOC,NOC,Year,sep='_')
ath2C<-data.frame(ath2B[,1],ath2B[,3])
ath3<-merge(ath2C,ath1B,by="NOC")
ath3["Fscore"]=ath3[,2]/ath3[,3]
View(ath3)
ath3["Fscore"]=log(ath3[,2]/ath3[,3])
ath3["Fscore"]=ln(ath3[,2]/ath3[,3])
ath3["Fscore"]=log10(ath3[,2]/ath3[,3])
ath3["Fscore"]=(ath3[,2]/ath3[,3])
gender_map%>%
filter(Series.Name == 'Employers, female (% of female employment) (modeled ILO estimate)')%>%
select('2016')%>%
ggplot() +
geom_sf(aes(fill=`2010`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
#plotting
gender_map%>%
filter(Series.Name == 'Employers, female (% of female employment) (modeled ILO estimate)')%>%
select('2016')%>%
ggplot() +
geom_sf(aes(fill=`2016`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
gender_map%>%
filter(Series.Name == 'Employers, female (% of female employment) (modeled ILO estimate)')
gender_map%>%
filter(Series.Name == 'Employers, female (% of female employment) (modeled ILO estimate)')%>%
select('2014')
gender_map%>%
filter(Series.Name == 'Employers, female (% of female employment) (modeled ILO estimate)')%>%
select('2014')%>%
ggplot() +
geom_sf(aes(fill=`2014`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
setwd("D:/2018.07 R_DataAnalysis/2018SUMMER_R/data")
#import data
library(sf)
library(ggplot2)
worldmap <- st_read("TM_WORLD_BORDERS-0.3.shp",stringsAsFactors=FALSE,quiet=TRUE)
names(worldmap)[3] <- paste('Country.Code')
worldmap <- st_transform(worldmap, "+init=esri:54030")
raw_gender <- read.csv('Gender_wewant.csv')
gender_map <- merge(worldmap, raw_gender, by="Country.Code")
library(stringr)
for (i in 15:ncol(gender_map)-1){
names(gender_map)[i] <- str_sub(names(gender_map)[i],-5,-2)
if((i >= 17) == (i < 41)){
gender_map[i+1] <- (gender_map[[i+1]] + gender_map[[i]] + gender_map[[i-1]] + gender_map[[i-2]]) /2
}
}
#plotting
gender_map%>%
filter(Series.Name == 'Expected years of schooling, female')%>%
select('2014')%>%
ggplot() +
geom_sf(aes(fill=`2014`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
gender_map%>%
filter(Series.Name == 'Expected years of schooling, female')
setwd("D:/2018.07 R_DataAnalysis/2018SUMMER_R/data")
#import data
library(sf)
library(ggplot2)
worldmap <- st_read("TM_WORLD_BORDERS-0.3.shp",stringsAsFactors=FALSE,quiet=TRUE)
names(worldmap)[3] <- paste('Country.Code')
worldmap <- st_transform(worldmap, "+init=esri:54030")
raw_gender <- read.csv('Gender_wewant.csv')
gender_map <- merge(worldmap, raw_gender, by="Country.Code")
library(stringr)
for (i in 15:ncol(gender_map)-1){
names(gender_map)[i] <- str_sub(names(gender_map)[i],-5,-2)
if((i >= 17) == (i < 41)){
gender_map[i+1] <- (gender_map[[i+1]] + gender_map[[i]] + gender_map[[i-1]] + gender_map[[i-2]]) /4
}
}
#plotting
gender_map%>%
filter(Series.Name == 'Expected years of schooling, female')%>%
select('2014')%>%
ggplot() +
geom_sf(aes(fill=`2014`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
#plotting
gender_map%>%
filter(Series.Name == 'Expected years of schooling, female')%>%
select('2010')%>%
ggplot() +
geom_sf(aes(fill=`2010`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
gender_map%>%
filter(Series.Name == 'Labor force, female (% of total labor force)')%>%
select('2010')%>%
ggplot() +
geom_sf(aes(fill=`2010`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
#plotting
gender_map%>%
filter(Series.Name == 'Adjusted net enrollment rate, primary, female (% of primary school age children)')%>%
select('2010')%>%
ggplot() +
geom_sf(aes(fill=`2010`))+
scale_fill_gradient(low = "#FFE4F3", high = "#F62018")
