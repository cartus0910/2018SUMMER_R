#移除標點符號 (punctuation)
#移除數字 (digits)、空白 (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
#移除可能有問題的符號
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, toSpace, "推")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "不")
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "都")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "很")
docs <- tm_map(docs, toSpace, "們")
docs <- tm_map(docs, toSpace, "到")
#移除標點符號 (punctuation)
#移除數字 (digits)、空白 (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
pttTestFunction <- function(URL, filename)
{
#URL   = "https://www.ptt.cc/bbs/NTUcourse/index.html"
html  = read_html(URL)
title = html_nodes(html, "a")
href  = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)),
href = href)
data = data[-c(1:10),]
getContent <- function(x) {
url  = paste0("https://www.ptt.cc", x)
tag  = html_node(read_html(url), 'div#main-content.bbs-screen.bbs-content')
text = toUTF8(html_text(tag))
}
#getContent(data$href[1])
allText = sapply(data$href, getContent)
allText
#out <- file(filename, "w", encoding="BIG-5")
write.table(allText, filename)
#close(out)
}
library(xml2)
library(tmcn)
library(rvest)
id = c(1:5)
URL = paste0("https://www.ptt.cc/bbs/Japan_Travel/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
#create wordcloud
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
#create wordcloud
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
#calculate words
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
#simplify the data
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
#移除可能有問題的符號
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, toSpace, "推")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "不")
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "都")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "很")
docs <- tm_map(docs, toSpace, "們")
docs <- tm_map(docs, toSpace, "到")
#移除標點符號 (punctuation)
#移除數字 (digits)、空白 (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
#Open html
library(xml2)
library(tmcn)
library(rvest)
id = c(1:5)
URL = paste0("https://www.ptt.cc/bbs/Japan_Travel/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
#Function
pttTestFunction <- function(URL, filename)
{
#URL   = "https://www.ptt.cc/bbs/NTUcourse/index.html"
html  = read_html(URL)
title = html_nodes(html, "a")
href  = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)),
href = href)
data = data[-c(1:10),]
getContent <- function(x) {
url  = paste0("https://www.ptt.cc", x)
tag  = html_node(read_html(url), 'div#main-content.bbs-screen.bbs-content')
text = toUTF8(html_text(tag))
}
#getContent(data$href[1])
allText = sapply(data$href, getContent)
allText
#out <- file(filename, "w", encoding="BIG-5")
write.table(allText, filename)
#close(out)
}
#Open html
library(xml2)
library(tmcn)
library(rvest)
id = c(1:5)
URL = paste0("https://www.ptt.cc/bbs/Japan_Travel/index", id, ".html")
filename = paste0(id, ".txt")
mapply(pttTestFunction,
URL = URL, filename = filename)
#simplify the data
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
#移除可能有問題的符號
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, toSpace, "推")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "不")
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "都")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "很")
docs <- tm_map(docs, toSpace, "們")
docs <- tm_map(docs, toSpace, "到")
#移除標點符號 (punctuation)
#移除數字 (digits)、空白 (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
#create wordcloud
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
#create wordcloud
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
#calculate words
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
#create wordcloud
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
#create wordcloud
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,words>2
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,min=2,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,min=4,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,min=2,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,min=2,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,min=2,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.2, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.8, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
par(family=("Heiti TC Light"))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
par(family=("Microsolf JengHei"))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
par(family=("Heiti TC Light"))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
install.packages('wordcloud2')
wordcloud2(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE, shape='triangle',size=0.3)
library(wordcloud2)
wordcloud2(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE, shape='triangle',size=0.3)
wordcloud2(freqFrame$Var1,freqFrame$Freq)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud2(freqFrame$Var1,freqFrame$Freq)
wordcloud2(freqFrame)
wordcloud2(freqFrame, minSize=10)
wordcloud2(freqFrame, minSize=10, fontFamily='Microsolf Jenghei')
wordcloud2(freqFrame, minSize=10, color='randon_dark')
wordcloud2(freqFrame, minSize=10, color='randon-dark')
wordcloud2(freqFrame, minSize=10, color='randon-dark')
wordcloud2(freqFrame, minSize=10)
wordcloud2(freqFrame, minSize=20, gridSize=20)
wordcloud2(freqFrame, minSize=10, gridSize=20)
wordcloud2(freqFrame, minSize=10, gridSize=5)
wordcloud2(shape='circle', freqFrame, minSize=10, gridSize=5)
wordcloud2(shape='circle', freqFrame, minSize=10, gridSize=10)
wordcloud2(fontFamily = "微软雅黑", shape='circle', freqFrame, minSize=10, gridSize=5)
wordcloud2(fontFamily = "微軟雅黑", shape='circle', freqFrame, minSize=10, gridSize=5)
wordcloud2(shape='star', freqFrame, minSize=10, gridSize=5)
wordcloud2(freqFrame, minSize=10, gridSize=5)
#create wordcloud
wordcloud2(freqFrame, minSize=10, gridSize=5)
View(freqFrame)
class(freqFrame)
new_freqFrame = subset(freqFrame, len(Var1)>=2)
new_freqFrame = subset(freqFrame, length(Var1)>=2)
wordcloud2(new_freqFrame, minSize=10, gridSize=5)
View(new_freqFrame)
View(new_freqFrame)
length('日本')
length('你')
c = ("日本", "你")
c = c("日本", "你")
lenght(c)
length(c)
setwd("D:/2018.07 R_DataAnalysis/2018SUMMER_R/data")
library("sf")
library("ggplot2")
worldmap <- st_read("countries.shp",stringsAsFactors=FALSE,quiet=TRUE)
worldmap <- st_transform(worldmap, "+init=esri:54030")
ggplot()+
geom_sf(data=worldmap)
raw_gender <- read.csv('Gender_wewant.csv')
test_gender <- read.csv('gender_test.csv')
View(test_gender)
test_gender <- read.csv('gender_test.csv')
View(test_gender)
test_map <- merge(worldmap, test_gender, by="CNTRY_NAME")
test_gender <- read.csv('gender_test.csv', coding='UTF-8')
test_gender <- read.csv('gender_test.csv', encoding ='UTF-8')
View(test_gender)
View(test_gender)
test_gender <- read.csv('gender_test.csv', filecoding ='UTF-8')
test_gender <- read.csv('gender_test.csv', fileEncoding ='UTF-8')
View(test_gender)
test_gender <- read.csv('gender_test.csv', Encoding ='UTF-8')
View(raw_gender)
test_gender <- read.csv('gender_test.csv')
View(test_gender)
column.name(test_gender)
name(test_gender)
names(test_gender)[1]
test_gender <- read.csv('gender_test.csv')
names(test_gender)[1]
names(test_gender)[1]
names(test_gender)[1] <- paste('Country.Code')
names(test_gender)[1] <- paste('Country.Name')
View(worldmap)
names(worldmap)[1] <- paste('Country.Name')
test_map <- merge(worldmap, test_gender, by="CNTRY_NAME")
test_map <- merge(worldmap, test_gender, by="Country.Name")
View(test_map)
ggplot()+
geom_sf(data=test_map)
ggplot()+
geom_sf(data=test_map, aes(fill=names(test_map)[6]))
ggplot()+
geom_sf(data=test_map, aes(fill=X2016.YR2016))
ggplot()+
geom_sf(data=test_map, aes(fill='X2016.YR2016.'))
ggplot()+
geom_sf(data=test_map, aes(fill='X2016..YR2016.'))
names(test_map)[6]
ggplot()+
geom_sf(data=test_map, aes(fill=X2016..YR2016.))
ggplot() +
geom_sf(data=test_map, aes(fill=X2016..YR2016.)) +
coord_sf() +
scale_fill_distiller(palette ='BrBG' ) +
theme_void()
as.numeric(test_map[6])
as.numeric(as.character(test_map[,6]))
ggplot() +
geom_sf(data=test_map, aes(fill=X2016..YR2016.)) +
coord_sf() +
scale_fill_distiller(palette ='BrBG' ) +
theme_void()
test_map$X2016..YR2016.=as.numeric(levels(test_map$X2016..YR2016.))[test_map$X2016..YR2016.]
ggplot() +
geom_sf(data=test_map, aes(fill=X2016..YR2016.))
test_map <- merge(worldmap, test_gender, by="Country.Name")
ggplot() +
geom_sf(data=test_map, aes(fill=X2016..YR2016.))
test_map$X2016..YR2016. <- as.numeric(levels(test_map$X2016..YR2016.))[test_map$X2016..YR2016.]
test_map$X2016..YR2016. <- suppressWarnings(as.numeric(levels(test_map$X2016..YR2016.))[test_map$X2016..YR2016.])
test_map$X2016..YR2016. <- suppressWarnings(as.numeric(
levels(test_map$X2016..YR2016.))[test_map$X2016..YR2016.])
test_map <- merge(worldmap, test_gender, by="Country.Name")
test_map$X2016..YR2016. <- suppressWarnings(as.numeric(
levels(test_map$X2016..YR2016.))[test_map$X2016..YR2016.])
View(test_map)
ggplot() +
geom_sf(data=test_map, aes(fill=X2016..YR2016.))
